fastapi>=0.68.0
uvicorn>=0.15.0
langchain>=0.0.200
langchain-community==0.0.10
langgraph==0.0.20
pymongo>=4.0.0
pydantic>=1.8.0
python-multipart==0.0.6
python-dotenv>=0.19.0
psutil>=5.8.0

# Llama dependencies (CPU optimized)
ollama>=0.1.0

# Optional: for local model files
# llama-cpp-python==0.2.20

# NO GPU dependencies needed!

# Optional: for GPU acceleration
# torch>=2.0.0
# transformers>=4.30.0 